{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"jiawei-ucas/ConsistentChat\")[\"train\"]\n",
    "\n",
    "# -------------------------\n",
    "# Pair conversations\n",
    "# -------------------------\n",
    "def to_pairs(conv):\n",
    "    pairs = []\n",
    "    i = 0\n",
    "    while i < len(conv) - 1:\n",
    "        if conv[i][\"from\"] == \"human\" and conv[i+1][\"from\"] == \"gpt\":\n",
    "            pairs.append([conv[i], conv[i+1]])\n",
    "            i += 2\n",
    "        else:\n",
    "            i += 1\n",
    "    return pairs\n",
    "\n",
    "# -------------------------\n",
    "# Merge helpers\n",
    "# -------------------------\n",
    "def merge_pairs(pairs):\n",
    "    return \"\\n\".join([f\"human: {h['value']}\\ngpt: {g['value']}\" for h,g in pairs])\n",
    "\n",
    "def merge_human(pairs):\n",
    "    return \"\\n\".join([f\"human: {h['value']}\" for h,_ in pairs])\n",
    "\n",
    "def merge_gpt(pairs):\n",
    "    return \"\\n\".join([f\"gpt: {g['value']}\" for _,g in pairs])\n",
    "\n",
    "# -------------------------\n",
    "# First + Last\n",
    "# -------------------------\n",
    "def first_last(pairs):\n",
    "    if len(pairs) <= 1:\n",
    "        return pairs\n",
    "    return [pairs[0], pairs[-1]]\n",
    "\n",
    "# -------------------------\n",
    "# Writer\n",
    "# -------------------------\n",
    "paths = {\n",
    "    \"full\": {\n",
    "        \"pair\": \"/home/hyang/BigML_sharding_dataset/Qwen3-VL-Embedding/data/consistent_chat/pair_full.jsonl\",\n",
    "        \"human\": \"/home/hyang/BigML_sharding_dataset/Qwen3-VL-Embedding/data/consistent_chat/human_full.jsonl\",\n",
    "        \"gpt\": \"/home/hyang/BigML_sharding_dataset/Qwen3-VL-Embedding/data/consistent_chat/gpt_full.jsonl\",\n",
    "    },\n",
    "    \"fl\": {\n",
    "        \"pair\": \"/home/hyang/BigML_sharding_dataset/Qwen3-VL-Embedding/data/consistent_chat/pair_first_last.jsonl\",\n",
    "        \"human\": \"/home/hyang/BigML_sharding_dataset/Qwen3-VL-Embedding/data/consistent_chat/human_first_last.jsonl\",\n",
    "        \"gpt\": \"/home/hyang/BigML_sharding_dataset/Qwen3-VL-Embedding/data/consistent_chat/gpt_first_last.jsonl\",\n",
    "    }\n",
    "}\n",
    "\n",
    "files = {\n",
    "    k: {kk: open(vv, \"w\") for kk, vv in v.items()}\n",
    "    for k, v in paths.items()\n",
    "}\n",
    "\n",
    "# -------------------------\n",
    "# Process\n",
    "# -------------------------\n",
    "for ex in ds:\n",
    "    pairs = to_pairs(ex[\"conversations\"])\n",
    "\n",
    "    # FULL\n",
    "    ex_pair = dict(ex);  ex_pair[\"conversations\"]  = merge_pairs(pairs)\n",
    "    ex_h    = dict(ex);  ex_h[\"conversations\"]     = merge_human(pairs)\n",
    "    ex_g    = dict(ex);  ex_g[\"conversations\"]     = merge_gpt(pairs)\n",
    "\n",
    "    files[\"full\"][\"pair\"].write(json.dumps(ex_pair)+\"\\n\")\n",
    "    files[\"full\"][\"human\"].write(json.dumps(ex_h)+\"\\n\")\n",
    "    files[\"full\"][\"gpt\"].write(json.dumps(ex_g)+\"\\n\")\n",
    "\n",
    "    # FIRST LAST\n",
    "    fl = first_last(pairs)\n",
    "\n",
    "    ex_pair = dict(ex);  ex_pair[\"conversations\"]  = merge_pairs(fl)\n",
    "    ex_h    = dict(ex);  ex_h[\"conversations\"]     = merge_human(fl)\n",
    "    ex_g    = dict(ex);  ex_g[\"conversations\"]     = merge_gpt(fl)\n",
    "\n",
    "    files[\"fl\"][\"pair\"].write(json.dumps(ex_pair)+\"\\n\")\n",
    "    files[\"fl\"][\"human\"].write(json.dumps(ex_h)+\"\\n\")\n",
    "    files[\"fl\"][\"gpt\"].write(json.dumps(ex_g)+\"\\n\")\n",
    "\n",
    "# close\n",
    "for group in files.values():\n",
    "    for f in group.values():\n",
    "        f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import json\n",
    "def load_jsonl(path):\n",
    "    data = []\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    return data\n",
    "def get_labels(data, key=\"intent\"):\n",
    "    return [x[key] for x in data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries: 14461\n",
      "Unique Intents: 9\n",
      "Unique Scenarios: 985\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# 1. Load the data\n",
    "query_data = load_jsonl(\"/home/hyang/BigML_sharding_dataset/Qwen3-VL-Embedding/data/consistent_chat/human_full.jsonl\")\n",
    "\n",
    "# 2. Extract and count unique Intents\n",
    "intents = get_labels(query_data, \"intent\")\n",
    "unique_intents = set(intents)\n",
    "\n",
    "# 3. Extract and count unique Scenarios (assuming 'scenario' is the key)\n",
    "scenarios = get_labels(query_data, \"scenario\")\n",
    "unique_scenarios = set(scenarios)\n",
    "\n",
    "print(f\"Total entries: {len(query_data)}\")\n",
    "print(f\"Unique Intents: {len(unique_intents)}\")\n",
    "print(f\"Unique Scenarios: {len(unique_scenarios)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python Qwen3-VL-Embedding/embed.py \\\n",
    "  --queries-file /home/hyang/BigML_sharding_dataset/Qwen3-VL-Embedding/data/consistent_chat/human_full.jsonl \\\n",
    "  --documents-file /home/hyang/BigML_sharding_dataset/Qwen3-VL-Embedding/data/consistent_chat/gpt_full.jsonl \\\n",
    "  --query-field query \\\n",
    "  --document-field document \\\n",
    "  --max-queries 1000 \\\n",
    "  --batch-size 32 \\\n",
    "  --output-dir Qwen3-VL-Embedding/outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CUDA_VISIBLE_DEVICES=4,5,6,7 torchrun --nproc-per-node=4 embed.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mint",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
